{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T18:31:47.035032200Z",
     "start_time": "2023-11-19T18:31:45.590897200Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Pipeline_preprocess_dataset_hc_new import Create_Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177f94cdde4cdc05",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load Iniziale Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42364f641b118fba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T18:31:47.180857400Z",
     "start_time": "2023-11-19T18:31:47.034040800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../data/Complete/DATASET_COMPLETO_HC.csv')\n",
    "df = pd.read_csv(r'C:\\Users\\AlessandroKuz\\Desktop\\ITS\\PW01 - Project Work\\ULTIMATE WORK\\Clean data and scripts\\HC_TRAIN_DF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fab24dcff99e8e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T18:31:47.180857400Z",
     "start_time": "2023-11-19T18:31:47.167899200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"LABEL\"] = df[\"LABEL\"].map({\"NEG\": 0, \"POS\": 1, \"VUS\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LABEL\n",
       "0    19566\n",
       "2      144\n",
       "1       11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['LABEL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b52ce09984cba657",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T18:31:47.196543700Z",
     "start_time": "2023-11-19T18:31:47.179859100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "masks_label = df['LABEL'] == 2\n",
    "pre_train_df, predict_df = df[~masks_label], df[masks_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60e68392b81bba22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T18:31:47.248905500Z",
     "start_time": "2023-11-19T18:31:47.201078300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = pre_train_df.drop(['LABEL'], axis=1), pre_train_df['LABEL']\n",
    "X_pred, y_pred = predict_df.drop(['LABEL'], axis=1), predict_df['LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21c89de8906713d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T18:31:47.274924600Z",
     "start_time": "2023-11-19T18:31:47.210636600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=21, stratify=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb44af1a4128f73",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Pipeline Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b72fff0b1e515ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T18:31:47.275948100Z",
     "start_time": "2023-11-19T18:31:47.242834600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_pipi = Create_Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c961f4162d58e3f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T18:31:51.829997700Z",
     "start_time": "2023-11-19T18:31:47.250906500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'STORIA_FAMILIARE_POS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\AlessandroKuz\\.conda\\envs\\projectWork\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'STORIA_FAMILIARE_POS'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\AlessandroKuz\\Desktop\\ITS\\PW01 - Project Work\\ULTIMATE WORK\\Clean data and scripts\\hc_machine_learning.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/AlessandroKuz/Desktop/ITS/PW01%20-%20Project%20Work/ULTIMATE%20WORK/Clean%20data%20and%20scripts/hc_machine_learning.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m X_train \u001b[39m=\u001b[39m my_pipi\u001b[39m.\u001b[39;49mfit_transform(X_train)\n",
      "File \u001b[1;32mc:\\Users\\AlessandroKuz\\.conda\\envs\\projectWork\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\AlessandroKuz\\.conda\\envs\\projectWork\\Lib\\site-packages\\sklearn\\pipeline.py:471\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model and transform with the final estimator.\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \n\u001b[0;32m    446\u001b[0m \u001b[39mFits all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    468\u001b[0m \u001b[39m    Transformed samples.\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    470\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m--> 471\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[0;32m    473\u001b[0m last_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\n\u001b[0;32m    474\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n",
      "File \u001b[1;32mc:\\Users\\AlessandroKuz\\.conda\\envs\\projectWork\\Lib\\site-packages\\sklearn\\pipeline.py:377\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    375\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[0;32m    376\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 377\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[0;32m    378\u001b[0m     cloned_transformer,\n\u001b[0;32m    379\u001b[0m     X,\n\u001b[0;32m    380\u001b[0m     y,\n\u001b[0;32m    381\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    382\u001b[0m     message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPipeline\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    383\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(step_idx),\n\u001b[0;32m    384\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps[name],\n\u001b[0;32m    385\u001b[0m )\n\u001b[0;32m    386\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32mc:\\Users\\AlessandroKuz\\.conda\\envs\\projectWork\\Lib\\site-packages\\joblib\\memory.py:353\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 353\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\AlessandroKuz\\.conda\\envs\\projectWork\\Lib\\site-packages\\sklearn\\pipeline.py:957\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    956\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 957\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m    958\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    959\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\AlessandroKuz\\.conda\\envs\\projectWork\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\AlessandroKuz\\.conda\\envs\\projectWork\\Lib\\site-packages\\sklearn\\base.py:916\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    914\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    915\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 916\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39;49mtransform(X)\n\u001b[0;32m    917\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    918\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\AlessandroKuz\\.conda\\envs\\projectWork\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\AlessandroKuz\\.conda\\envs\\projectWork\\Lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:240\u001b[0m, in \u001b[0;36mFunctionTransformer.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Transform X using the forward function.\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \n\u001b[0;32m    228\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39m    Transformed input.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    239\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_input(X, reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m--> 240\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(X, func\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc, kw_args\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkw_args)\n",
      "File \u001b[1;32mc:\\Users\\AlessandroKuz\\.conda\\envs\\projectWork\\Lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:312\u001b[0m, in \u001b[0;36mFunctionTransformer._transform\u001b[1;34m(self, X, func, kw_args)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[39mif\u001b[39;00m func \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    310\u001b[0m     func \u001b[39m=\u001b[39m _identity\n\u001b[1;32m--> 312\u001b[0m \u001b[39mreturn\u001b[39;00m func(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m(kw_args \u001b[39mif\u001b[39;49;00m kw_args \u001b[39melse\u001b[39;49;00m {}))\n",
      "File \u001b[1;32mc:\\Users\\AlessandroKuz\\Desktop\\ITS\\PW01 - Project Work\\ULTIMATE WORK\\Clean data and scripts\\Pipeline_preprocess_dataset_hc_new.py:153\u001b[0m, in \u001b[0;36mPreprocess_Dataset\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    131\u001b[0m df \u001b[39m=\u001b[39m rename_columns(\n\u001b[0;32m    132\u001b[0m     df,\n\u001b[0;32m    133\u001b[0m     [\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    142\u001b[0m     ],\n\u001b[0;32m    143\u001b[0m )\n\u001b[0;32m    145\u001b[0m fill_values \u001b[39m=\u001b[39m {\n\u001b[0;32m    146\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mSTORIA_FAMILIARE_POS\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m0\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    147\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mSEDE_TUMORE_FAMILIARITA\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mND\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mSTRAND\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m0\u001b[39m\n\u001b[0;32m    152\u001b[0m }\n\u001b[1;32m--> 153\u001b[0m df \u001b[39m=\u001b[39m fill_NaN_rows(df, fill_values)\n\u001b[0;32m    155\u001b[0m df \u001b[39m=\u001b[39m to_uppercase(df)\n\u001b[0;32m    157\u001b[0m columns_to_clean \u001b[39m=\u001b[39m [\n\u001b[0;32m    158\u001b[0m     (\n\u001b[0;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSEDE_TUMORE_FAMILIARITA\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    235\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mETA_DIAGNOSI\u001b[39m\u001b[39m\"\u001b[39m, {\u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mN.D\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mND\u001b[39m\u001b[39m\"\u001b[39m}),\n\u001b[0;32m    236\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\AlessandroKuz\\Desktop\\ITS\\PW01 - Project Work\\ULTIMATE WORK\\Clean data and scripts\\Pipeline_preprocess_dataset_hc_new.py:61\u001b[0m, in \u001b[0;36mfill_NaN_rows\u001b[1;34m(df, fill_values)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfill_NaN_rows\u001b[39m(df, fill_values):\n\u001b[0;32m     60\u001b[0m     \u001b[39mfor\u001b[39;00m column, value \u001b[39min\u001b[39;00m fill_values\u001b[39m.\u001b[39mitems():\n\u001b[1;32m---> 61\u001b[0m         df[column]\u001b[39m.\u001b[39mfillna(value, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     62\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\AlessandroKuz\\.conda\\envs\\projectWork\\Lib\\site-packages\\pandas\\core\\frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3896\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3897\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3898\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\AlessandroKuz\\.conda\\envs\\projectWork\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'STORIA_FAMILIARE_POS'"
     ]
    }
   ],
   "source": [
    "X_train = my_pipi.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colonne_fam = []\n",
    "# for col in X_train.columns:\n",
    "#     if col.startswith('SEDE_TUMORE_FAMILIARITA'):\n",
    "#         colonne_fam.append(col)\n",
    "#     elif col.startswith('AOP'):\n",
    "#         colonne_fam.append(col)\n",
    "# # colonne_fam\n",
    "\n",
    "for col in X_train.columns:\n",
    "    if col.startswith('AOP'):\n",
    "        X_test[col] = 0\n",
    "        X_val[col] = 0\n",
    "    elif col.startswith('SEDE_TUMORE_FAMILIARITA'):\n",
    "        X_test[col] = 0\n",
    "        X_val[col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in colonne_fam:\n",
    "#     print(X_train[column].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in colonne_fam:\n",
    "#     if col not in X_test.columns:\n",
    "#         X_test[col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b2a065cea6d61d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T18:31:53.323430500Z",
     "start_time": "2023-11-19T18:31:51.829008600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = my_pipi.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = my_pipi.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a57bfcf0766656",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Selezione Modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588a5b05e6406556",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "random_forest = RandomForestClassifier()\n",
    "logistic_regression = LogisticRegression()\n",
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f0f85fdabb00c0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Splitting Normale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca125e2a7c606cb6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_forest_test = random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94beff05af2b8a2c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_forest_test.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = random_forest_test.predict(X_val)\n",
    "# getting unique values of the numpy array\n",
    "# np.unique(predictions, return_counts=True)\n",
    "# getting the row where the value is 1\n",
    "np.where(predictions == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_train.columns:\n",
    "    if col.startswith('AOP'):\n",
    "        X_pred[col] = 0\n",
    "    elif col.startswith('SEDE_TUMORE_FAMILIARITA'):\n",
    "        X_pred[col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = my_pipi.transform(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = random_forest_test.predict(X_pred)\n",
    "\n",
    "np.unique(predictions, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b464c08a953600f6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Splitting con K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532c6878f61caf05",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_fold = StratifiedKFold(n_splits=10, random_state=21, shuffle=True)\n",
    "val_fold = StratifiedKFold(n_splits=10, random_state=21, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49552096c40bc9d4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, (train_index, test_index) in enumerate(train_fold.split(X, X['STRATIFY_COL'])):\n",
    "    X_train_temp, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train_temp, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    for j, (train_index, val_index) in enumerate(val_fold.split(X_train_temp, X_train_temp['STRATIFY_COL'])):\n",
    "        X_train, X_val = X_train_temp.iloc[train_index], X_train_temp.iloc[val_index]\n",
    "        y_train, y_val = y_train_temp.iloc[train_index], y_train_temp.iloc[val_index]\n",
    "\n",
    "        # Model training and evaluation\n",
    "        random_forest = RandomForestClassifier()\n",
    "        random_forest_test = random_forest.fit(X_train, y_train)\n",
    "        score = random_forest_test.score(X_val, y_val)\n",
    "\n",
    "        # Model prediction\n",
    "        predictions = random_forest_test.predict(X_pred)\n",
    "\n",
    "        # Model evaluation\n",
    "        np.unique(predictions, return_counts=True)\n",
    "\n",
    "        # Save model\n",
    "        import pickle\n",
    "\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
